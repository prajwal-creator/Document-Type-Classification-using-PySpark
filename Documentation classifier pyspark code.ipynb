{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "121d4f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('C:/extras/spark')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93a59a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark=SparkSession.builder\\\n",
    "                          .appName('classifier')\\\n",
    "                          .getOrCreate()\n",
    "sc=spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aaa74e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.feature import *\n",
    "from pyspark.ml.classification import *\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\n",
    "from pyspark.ml.feature import HashingTF, IDF\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "716abc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bfd259e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fas_df = spark.read.text('Data/Fashion/*')\n",
    "fas_df = fas_df.withColumn(\"category\",lit(\"Fashion\"))\n",
    "\n",
    "tech_df = spark.read.text('Data/Technology/*')\n",
    "tech_df = tech_df.withColumn(\"category\",lit(\"Technology\"))\n",
    "\n",
    "sci_df = spark.read.text('Data/Science/*')\n",
    "sci_df = sci_df.withColumn(\"category\",lit(\"science\"))\n",
    "\n",
    "mov_df = spark.read.text('Data/Movie/*')\n",
    "mov_df = mov_df.withColumn(\"category\",lit(\"Movie\"))\n",
    "\n",
    "\n",
    "merge_df1 = fas_df.union(tech_df)\n",
    "merge_df2 = merge_df1.union(sci_df)\n",
    "merge_df3 = merge_df2.union(mov_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb295cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+\n",
      "|               value|category|\n",
      "+--------------------+--------+\n",
      "|   Sections SEARC...| Fashion|\n",
      "|   Sections SEARC...| Fashion|\n",
      "|   Sections SEARC...| Fashion|\n",
      "|   Sections SEARC...| Fashion|\n",
      "|   Sections SEARC...| Fashion|\n",
      "+--------------------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = merge_df3.select([column for column in merge_df3.columns])\n",
    "data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51853548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+\n",
      "|               value|category|\n",
      "+--------------------+--------+\n",
      "|   Sections SEARC...| Fashion|\n",
      "|   Sections SEARC...| Fashion|\n",
      "|   Sections SEARC...| Fashion|\n",
      "|   Sections SEARC...| Fashion|\n",
      "|   Sections SEARC...| Fashion|\n",
      "+--------------------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Fas_udf = spark.read.text('Data/unknown/Fashion/*')\n",
    "Fas_udf = Fas_udf.withColumn(\"category\",lit(\"Fashion\"))\n",
    "\n",
    "science_udf = spark.read.text('Data/unknown/science/*')\n",
    "science_udf = science_udf.withColumn(\"category\",lit(\"science\"))\n",
    "\n",
    "tech_udf = spark.read.text('Data/unknown/technology/*')\n",
    "tech_udf = tech_udf.withColumn(\"category\",lit(\"technology\"))\n",
    "\n",
    "movie_udf = spark.read.text('Data/unknown/Movie/*')\n",
    "movie_udf = movie_udf.withColumn(\"category\",lit(\"Movie\"))\n",
    "\n",
    "merge_udf1 = Fas_udf.union(science_udf)\n",
    "merge_udf2 = merge_udf1.union(tech_udf)\n",
    "merge_udf3 = merge_udf2.union(movie_udf)\n",
    "\n",
    "unknown_data = merge_udf3.select([column for column in merge_udf3.columns])\n",
    "unknown_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e116b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "regexTokenizer = RegexTokenizer(inputCol=\"value\", outputCol=\"words\", pattern=\"\\\\W\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e250ffc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')\n",
    "\n",
    "add_stopwords=nltk.corpus.stopwords.words('english')\n",
    "add_stopwords_1 = [\"nytimes\",\"com\",\"sense\",\"day\",\"common\",\"business\",\"todays\",\"said\",\"food\",\"review\",\"sunday\",\"letters\",\"politics\",\"events\",\"terms\",\"services\",\"years\",\"contributors\",\"companies\",\"listings\",\"applications\",\"tax\",\"trump\",\"president\",\"contributing\",\"make\",\"think\",\"woman\",\"federal\",\"called\",\"system\",\"found\",\"american\",\"sale\",\"headline\",\"arts\",\"times\",\"subscriptions\",\"choices\",\"privacy\",\"take\",\"jobs\",\"books\",\"account\",\"accounts\",\"television\",\"nyc\",\"writers\",\"multimedia\",\"journeys\",\"editorials\",\"photography\",\"automobiles\",\"paper\",\"city\",\"tool\",\"sports\",\"weddings\",\"columnists\",\"contribution\",\"even\",\"nyt\",\"obituary\",\"state\",\"travel\",\"advertise\",\"pm\",\"street\",\"go\",\"corrections\",\"saturday\",\"company\",\"dance\",\"states\",\"real\",\"movies\",\"estate\",\"percent\",\"music\",\"tech\",\"living\",\"science\",\"fashion\",\"please\",\"opinion\",\"art\",\"new\",\"york\",\"time\",\"u\",\"wa\",\"reading\",\"ha\",\"video\",\"image\",\"photo\",\"credit\",\"edition\",\"magazine\",\"oped\",\"could\",\"crossword\",\"mr\",\"term\",\"feedback\",\"index\",\"get\",\"also\",\"b\",\"help\",\"year\",\"health\",\"united\",\"education\",\"week\",\"think\",\"guide\",\"event\",\"two\",\"first\",\"subscription\",\"service\",\"cut\",\"is\",\"nytimescom\",\"section\",\"sections\",\"Sections\",\"Home\",\"home\",\"Search\",\"search\",\"Skip\",\"skip\",\"content\",\"navigation\",\"View\",\"view\",\"mobile\",\"version\",\"Subscribe\",\"subscribe\",\"Now\",\"now\",\"Log\",\"log\",\"In\",\"in\",\"setting\",\"settings\",\"Site\",\"site\",\"Loading\",\"loading\",\"article\",\"next\",\"previous\",\"Advertisement\",\"ad\",\"advertisement\",\"Supported\",\"supported\",\"by\",\"Share\",\"share\",\"Page\",\"page\",\"Continue\",\"continue\",\"main\",\"story\",\"newsletter\",\"Sign\",\"Up\",\"Manage\",\"email\",\"preferences\",\"Not\",\"you\",\"opt\",\"out\",\"contact\",\"us\",\"anytime\",\"thank\",\"subscribing\",\"see\",\"more\",\"email\"] \n",
    "stopwordsRemover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered1\").setStopWords(add_stopwords)\n",
    "stopwordsRemover1 = StopWordsRemover(inputCol=\"filtered1\", outputCol=\"filtered\").setStopWords(add_stopwords_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80359599",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_stringIdx = StringIndexer(inputCol = \"category\", outputCol = \"label\")\n",
    "hashingTF = HashingTF(inputCol=\"filtered\", outputCol=\"rawFeatures\", numFeatures=1000)\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\", minDocFreq=5) #minDocFreq: remove sparse terms\n",
    "pipeline = Pipeline(stages=[regexTokenizer, stopwordsRemover,stopwordsRemover1, hashingTF, idf, label_stringIdx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d210477",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelineFit = pipeline.fit(data)\n",
    "dataset = pipelineFit.transform(data)\n",
    "(trainingData, testData) = dataset.randomSplit([0.8, 0.2], seed = 100)\n",
    "lr = LogisticRegression(maxIter=20, regParam=0.3, elasticNetParam=0)\n",
    "lrModel = lr.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1916e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+--------+------------------------------+-----+----------+\n",
      "|                         value|category|                   probability|label|prediction|\n",
      "+------------------------------+--------+------------------------------+-----+----------+\n",
      "|   Sections SEARCH Skip to ...|   Movie|[0.9822394802109057,0.00235...|  0.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...|   Movie|[0.9811567547470802,0.00302...|  0.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...|   Movie|[0.9770537920390813,0.00631...|  0.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...|   Movie|[0.9763162809849949,0.01115...|  0.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...|   Movie|[0.9762569248827576,0.00562...|  0.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...|   Movie|[0.970554468408183,0.009335...|  0.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...|   Movie|[0.9679333738863134,0.00870...|  0.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...|   Movie|[0.9669405158721934,0.00738...|  0.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...|   Movie|[0.9635934697853594,0.00953...|  0.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...|   Movie|[0.957076942799982,0.008945...|  0.0|       0.0|\n",
      "+------------------------------+--------+------------------------------+-----+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_train = lrModel.transform(trainingData)\n",
    "predictions_train.filter(predictions_train['prediction'] == 0) \\\n",
    "    .select(\"value\",\"category\",\"probability\",\"label\",\"prediction\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(n = 10, truncate = 30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0be47594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------Accuracy of train data using logistic_regression-----: 98.76222962433778%\n"
     ]
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "print(\"-------Accuracy of train data using logistic_regression-----: \" + str(evaluator.evaluate(predictions_train)*100)+\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8debf96b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+--------+------------------------------+-----+----------+\n",
      "|                         value|category|                   probability|label|prediction|\n",
      "+------------------------------+--------+------------------------------+-----+----------+\n",
      "|   Sections SEARCH Skip to ...|   Movie|[0.9754632623041882,0.01057...|  0.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...|   Movie|[0.9431747402417925,0.02006...|  0.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...|   Movie|[0.9172397458630736,0.02471...|  0.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...|   Movie|[0.9053576601908154,0.02005...|  0.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...|   Movie|[0.8962780254409616,0.02195...|  0.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...|   Movie|[0.8507710146790355,0.01021...|  0.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...|   Movie|[0.8454293725021643,0.05217...|  0.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...|   Movie|[0.8197670154180591,0.01462...|  0.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...|   Movie|[0.8190208403033724,0.04383...|  0.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...|   Movie|[0.8129886620616786,0.04727...|  0.0|       0.0|\n",
      "+------------------------------+--------+------------------------------+-----+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = lrModel.transform(testData)\n",
    "predictions.filter(predictions['prediction'] == 0) \\\n",
    "    .select(\"value\",\"category\",\"probability\",\"label\",\"prediction\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(n = 10, truncate = 30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e98a5304",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelineFit2 = pipeline.fit(unknown_data)\n",
    "unknown_dataset = pipelineFit2.transform(unknown_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a2490fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+-----------+-----+----------+\n",
      "|value|category|probability|label|prediction|\n",
      "+-----+--------+-----------+-----+----------+\n",
      "+-----+--------+-----------+-----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions2 = lrModel.transform(unknown_dataset)\n",
    "predictions2.filter(predictions2['prediction'] == 0) \\\n",
    "    .select(\"value\",\"category\",\"probability\",\"label\",\"prediction\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(n = 10, truncate = 30)\n",
    "predictions2.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa2e023f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------Accuracy of test data using logistic_regression-----: 64.6386141204794%\n",
      "-------Accuracy of unknown data using logistic_regression-----: 13.2128740824393%\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "print(\"-------Accuracy of test data using logistic_regression-----: \" + str(evaluator.evaluate(predictions)*100)+\"%\")\n",
    "\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "print(\"-------Accuracy of unknown data using logistic_regression-----: \" + str(evaluator.evaluate(predictions2)*100)+\"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9729a56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training the data -- Naive Bayes\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "nb = NaiveBayes(smoothing=1)\n",
    "model = nb.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a718aaae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+--------+------------------------------+-----+----------+\n",
      "|                         value|category|                   probability|label|prediction|\n",
      "+------------------------------+--------+------------------------------+-----+----------+\n",
      "|   Sections SEARCH Skip to ...|   Movie|[1.0,1.0348354707598595E-18...|  0.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...|   Movie|[1.0,7.365373813070062E-21,...|  0.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...|   Movie|[1.0,2.0192994705203615E-23...|  0.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...|   Movie|[1.0,9.314255596200951E-24,...|  0.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...|   Movie|[1.0,4.686775487333476E-24,...|  0.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...|   Movie|[1.0,6.131923885718499E-26,...|  0.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...|   Movie|[1.0,3.8235683097586036E-28...|  0.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...|   Movie|[1.0,5.44902143952754E-29,1...|  0.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...|   Movie|[1.0,4.7338273688085696E-30...|  0.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...|   Movie|[1.0,4.110241094211335E-30,...|  0.0|       0.0|\n",
      "+------------------------------+--------+------------------------------+-----+----------+\n",
      "only showing top 10 rows\n",
      "\n",
      "-------Accuracy of train data using logistic_regression-----: 93.01496019989493%\n"
     ]
    }
   ],
   "source": [
    "predictions_train = model.transform(trainingData)\n",
    "predictions_train.filter(predictions_train['prediction'] == 0) \\\n",
    "    .select(\"value\",\"category\",\"probability\",\"label\",\"prediction\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(n = 10, truncate = 30)\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "print(\"-------Accuracy of train data using logistic_regression-----: \" + str(evaluator.evaluate(predictions_train)*100)+\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a53ddbe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+----------+------------------------------+-----+----------+\n",
      "|                         value|  category|                   probability|label|prediction|\n",
      "+------------------------------+----------+------------------------------+-----+----------+\n",
      "|   Sections SEARCH Skip to ...|   Fashion|[1.0,1.7849695897712397E-17...|  1.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...|     Movie|[1.0,5.286020787858083E-18,...|  0.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...|     Movie|[1.0,4.703611074610709E-22,...|  0.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...|     Movie|[1.0,6.492341445916501E-27,...|  0.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...|     Movie|[1.0,4.248773392621757E-29,...|  0.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...|     Movie|[1.0,7.00353830988496E-31,2...|  0.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...|     Movie|[1.0,8.202852029206588E-34,...|  0.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...|     Movie|[1.0,2.7184097459394804E-39...|  0.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...|     Movie|[1.0,1.017433094930809E-49,...|  0.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...|Technology|[1.0,2.6266823734693287E-50...|  2.0|       0.0|\n",
      "+------------------------------+----------+------------------------------+-----+----------+\n",
      "only showing top 10 rows\n",
      "\n",
      "+--------------------+--------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+--------------------+--------------------+----------+\n",
      "|               value|category|               words|           filtered1|            filtered|         rawFeatures|            features|label|       rawPrediction|         probability|prediction|\n",
      "+--------------------+--------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+--------------------+--------------------+----------+\n",
      "|   Sections SEARC...| Fashion|[sections, search...|[sections, search...|[today, ball, tue...|(1000,[7,19,22,76...|(1000,[7,19,22,76...|  1.0|[-1577.8179463150...|[4.09853561061001...|       1.0|\n",
      "|   Sections SEARC...| Fashion|[sections, search...|[sections, search...|[today, dress, li...|(1000,[12,53,78,8...|(1000,[12,53,78,8...|  1.0|[-1450.1415314949...|[0.99999999996922...|       0.0|\n",
      "|   Sections SEARC...| Fashion|[sections, search...|[sections, search...|[today, hold, sho...|(1000,[15,19,22,7...|(1000,[15,19,22,7...|  1.0|[-1684.9339721788...|[3.43726962705625...|       1.0|\n",
      "|   Sections SEARC...| Fashion|[sections, search...|[sections, search...|[today, biz, like...|(1000,[19,24,26,7...|(1000,[19,24,26,7...|  1.0|[-1757.1593992245...|[0.66804611483392...|       0.0|\n",
      "|   Sections SEARC...| Fashion|[sections, search...|[sections, search...|[today, racial, m...|(1000,[19,78,80,8...|(1000,[19,78,80,8...|  1.0|[-1181.8983006118...|[3.95214645651776...|       1.0|\n",
      "|   Sections SEARC...| Fashion|[sections, search...|[sections, search...|[today, westward,...|(1000,[10,47,78,8...|(1000,[10,47,78,8...|  1.0|[-1193.4933078723...|[0.99999979355994...|       0.0|\n",
      "|   Sections SEARC...| Fashion|[sections, search...|[sections, search...|[today, auxiliary...|(1000,[10,19,38,5...|(1000,[10,19,38,5...|  1.0|[-1206.7768403631...|[6.59924183199681...|       1.0|\n",
      "|   Sections SEARC...| Fashion|[sections, search...|[sections, search...|[today, display, ...|(1000,[19,23,78,8...|(1000,[19,23,78,8...|  1.0|[-1114.3597115074...|[1.21068204998434...|       1.0|\n",
      "|   Sections SEARC...| Fashion|[sections, search...|[sections, search...|[today, fete, ass...|(1000,[10,19,78,8...|(1000,[10,19,78,8...|  1.0|[-1045.5884000333...|[1.49324749400894...|       1.0|\n",
      "|   Sections SEARC...| Fashion|[sections, search...|[sections, search...|[today, junior, m...|(1000,[45,49,71,7...|(1000,[45,49,71,7...|  1.0|[-1579.0910213747...|[4.24176246361850...|       3.0|\n",
      "+--------------------+--------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+--------------------+--------------------+----------+\n",
      "only showing top 10 rows\n",
      "\n",
      "-------Accuracy of test data using naive_bayes-----: 58.8554632688887%\n"
     ]
    }
   ],
   "source": [
    "predictions3 = model.transform(testData)\n",
    "predictions3.filter(predictions3['prediction'] == 0) \\\n",
    "    .select(\"value\",\"category\",\"probability\",\"label\",\"prediction\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(n = 10, truncate = 30)\n",
    "predictions3.show(10)\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "print(\"-------Accuracy of test data using naive_bayes-----: \" + str(evaluator.evaluate(predictions3)*100)+\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "da10c68a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+--------+------------------------------+-----+----------+\n",
      "|                         value|category|                   probability|label|prediction|\n",
      "+------------------------------+--------+------------------------------+-----+----------+\n",
      "|   Sections SEARCH Skip to ...|   Movie|[0.9572707190900996,0.03799...|  0.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...|   Movie|[0.9200992619781946,0.03093...|  0.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...| science|[0.8060914009544183,0.00356...|  1.0|       0.0|\n",
      "+------------------------------+--------+------------------------------+-----+----------+\n",
      "\n",
      "-------Accuracy of unknown data using naive_bayes-----: 31.242077171133104%\n"
     ]
    }
   ],
   "source": [
    "predictions4 = model.transform(unknown_dataset)\n",
    "predictions4.filter(predictions4['prediction'] == 0) \\\n",
    "    .select(\"value\",\"category\",\"probability\",\"label\",\"prediction\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(n = 10, truncate = 30)\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "print(\"-------Accuracy of unknown data using naive_bayes-----: \" + str(evaluator.evaluate(predictions4)*100)+\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d5efa4b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+--------+-----------------+-----+----------+\n",
      "|                         value|category|      probability|label|prediction|\n",
      "+------------------------------+--------+-----------------+-----+----------+\n",
      "|   Sections SEARCH Skip to ...|   Movie|[1.0,0.0,0.0,0.0]|  0.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...|   Movie|[1.0,0.0,0.0,0.0]|  0.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...|   Movie|[1.0,0.0,0.0,0.0]|  0.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...|   Movie|[1.0,0.0,0.0,0.0]|  0.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...|   Movie|[1.0,0.0,0.0,0.0]|  0.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...|   Movie|[1.0,0.0,0.0,0.0]|  0.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...|   Movie|[1.0,0.0,0.0,0.0]|  0.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...|   Movie|[1.0,0.0,0.0,0.0]|  0.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...|   Movie|[1.0,0.0,0.0,0.0]|  0.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...|   Movie|[1.0,0.0,0.0,0.0]|  0.0|       0.0|\n",
      "+------------------------------+--------+-----------------+-----+----------+\n",
      "only showing top 10 rows\n",
      "\n",
      "-------Accuracy of train data using Decision Tree-----: 68.25192028280541%\n",
      "+------------------------------+--------+-----------------+-----+----------+\n",
      "|                         value|category|      probability|label|prediction|\n",
      "+------------------------------+--------+-----------------+-----+----------+\n",
      "|   Sections SEARCH Skip to ...|   Movie|[1.0,0.0,0.0,0.0]|  0.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...|   Movie|[1.0,0.0,0.0,0.0]|  0.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...|   Movie|[1.0,0.0,0.0,0.0]|  0.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...|   Movie|[1.0,0.0,0.0,0.0]|  0.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...|   Movie|[1.0,0.0,0.0,0.0]|  0.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...|   Movie|[1.0,0.0,0.0,0.0]|  0.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...|   Movie|[1.0,0.0,0.0,0.0]|  0.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...|   Movie|[1.0,0.0,0.0,0.0]|  0.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...|   Movie|[1.0,0.0,0.0,0.0]|  0.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...|   Movie|[1.0,0.0,0.0,0.0]|  0.0|       0.0|\n",
      "+------------------------------+--------+-----------------+-----+----------+\n",
      "only showing top 10 rows\n",
      "\n",
      "-------Accuracy of test data using Decision Tree-----: 60.854299475524165%\n",
      "+------------------------------+--------+------------------------------+-----+----------+\n",
      "|                         value|category|                   probability|label|prediction|\n",
      "+------------------------------+--------+------------------------------+-----+----------+\n",
      "|   Sections SEARCH Skip to ...| Fashion|[0.4090909090909091,0.40909...|  3.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...| science|[0.4090909090909091,0.40909...|  1.0|       0.0|\n",
      "+------------------------------+--------+------------------------------+-----+----------+\n",
      "\n",
      "-------Accuracy of unknown data using Decision Tree-----: 27.29935032483758%\n"
     ]
    }
   ],
   "source": [
    "#training the data using Decision Tree Classifier\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "pipelineFit_dt = pipeline.fit(data)\n",
    "dataset = pipelineFit_dt.transform(data)\n",
    "(trainingData, testData) = dataset.randomSplit([0.8, 0.2], seed = 100)\n",
    "dt = DecisionTreeClassifier(impurity=\"gini\")\n",
    "dtModel = dt.fit(trainingData)\n",
    "\n",
    "predictions_dt = dtModel.transform(trainingData)\n",
    "predictions_dt.filter(predictions_dt['prediction'] == 0) \\\n",
    "    .select(\"value\",\"category\",\"probability\",\"label\",\"prediction\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(n = 10, truncate = 30)\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "print(\"-------Accuracy of train data using Decision Tree-----: \" + str(evaluator.evaluate(predictions_dt)*100)+\"%\")\n",
    "\n",
    "\n",
    "predictions = dtModel.transform(testData)\n",
    "predictions.filter(predictions['prediction'] == 0) \\\n",
    "    .select(\"value\",\"category\",\"probability\",\"label\",\"prediction\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(n = 10, truncate = 30)\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "print(\"-------Accuracy of test data using Decision Tree-----: \" + str(evaluator.evaluate(predictions)*100)+\"%\")\n",
    "\n",
    "\n",
    "pipelineFit2 = pipeline.fit(unknown_data)\n",
    "unknown_dataset = pipelineFit2.transform(unknown_data)\n",
    "predictions2 = dtModel.transform(unknown_dataset)\n",
    "predictions2.filter(predictions2['prediction'] == 0) \\\n",
    "    .select(\"value\",\"category\",\"probability\",\"label\",\"prediction\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(n = 10, truncate = 30)\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "print(\"-------Accuracy of unknown data using Decision Tree-----: \" + str(evaluator.evaluate(predictions2)*100)+\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "84ecab1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+--------+------------------------------+-----+----------+\n",
      "|                         value|category|                   probability|label|prediction|\n",
      "+------------------------------+--------+------------------------------+-----+----------+\n",
      "|   Sections SEARCH Skip to ...|   Movie|[0.6398705677894322,0.13560...|  0.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...|   Movie|[0.6227305732576371,0.12748...|  0.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...|   Movie|[0.6227158003340711,0.15309...|  0.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...|   Movie|[0.6154696010362707,0.13968...|  0.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...|   Movie|[0.5852354309301614,0.15176...|  0.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...|   Movie|[0.5812419180480376,0.14512...|  0.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...|   Movie|[0.577175668620227,0.164575...|  0.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...|   Movie|[0.5765341565550058,0.16046...|  0.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...|   Movie|[0.5746639811963054,0.15903...|  0.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...|   Movie|[0.5742245313185417,0.17050...|  0.0|       0.0|\n",
      "+------------------------------+--------+------------------------------+-----+----------+\n",
      "only showing top 10 rows\n",
      "\n",
      "-------Accuracy of train data using Random Forest-----: 66.78102182507108%\n",
      "+------------------------------+--------+------------------------------+-----+----------+\n",
      "|                         value|category|                   probability|label|prediction|\n",
      "+------------------------------+--------+------------------------------+-----+----------+\n",
      "|   Sections SEARCH Skip to ...|   Movie|[0.5734915360694213,0.16141...|  0.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...|   Movie|[0.5675465557586775,0.15006...|  0.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...|   Movie|[0.5482683483338631,0.17620...|  0.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...|   Movie|[0.5369476010768656,0.14659...|  0.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...|   Movie|[0.5244973064776545,0.17757...|  0.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...|   Movie|[0.4865085155160294,0.21724...|  0.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...|   Movie|[0.4829307582860207,0.23204...|  0.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...|   Movie|[0.47239848891421077,0.1739...|  0.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...|   Movie|[0.4694667794161258,0.21029...|  0.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...|   Movie|[0.4648452510077542,0.13808...|  0.0|       0.0|\n",
      "+------------------------------+--------+------------------------------+-----+----------+\n",
      "only showing top 10 rows\n",
      "\n",
      "-------Accuracy of test data using Random Forest-----: 53.488746162139236%\n",
      "+------------------------------+--------+------------------------------+-----+----------+\n",
      "|                         value|category|                   probability|label|prediction|\n",
      "+------------------------------+--------+------------------------------+-----+----------+\n",
      "|   Sections SEARCH Skip to ...|   Movie|[0.34660649530416576,0.2772...|  0.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...|   Movie|[0.33908390638307784,0.2242...|  0.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...|   Movie|[0.32972099439480546,0.2512...|  0.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...| science|[0.3291258821252629,0.25405...|  1.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...| science|[0.3206019511525506,0.21386...|  1.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...|   Movie|[0.3177518743948406,0.23449...|  0.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...|   Movie|[0.31468145185962926,0.2389...|  0.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...| Fashion|[0.31468145185962926,0.2389...|  3.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...| science|[0.31468145185962926,0.2389...|  1.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...|   Movie|[0.3128656912646792,0.26970...|  0.0|       0.0|\n",
      "+------------------------------+--------+------------------------------+-----+----------+\n",
      "only showing top 10 rows\n",
      "\n",
      "-------Accuracy of unknown data using Decision Tree-----: 37.18628490632733%\n"
     ]
    }
   ],
   "source": [
    "#training the data using Random Forest Classifier\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "pipelineFit_rf = pipeline.fit(data)\n",
    "dataset = pipelineFit_rf.transform(data)\n",
    "(trainingData, testData) = dataset.randomSplit([0.8, 0.2], seed = 100)\n",
    "rf = RandomForestClassifier(numTrees=50)\n",
    "rfModel = rf.fit(trainingData)\n",
    "\n",
    "predictions_rf = rfModel.transform(trainingData)\n",
    "predictions_rf.filter(predictions_rf['prediction'] == 0) \\\n",
    "    .select(\"value\",\"category\",\"probability\",\"label\",\"prediction\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(n = 10, truncate = 30)\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "print(\"-------Accuracy of train data using Random Forest-----: \" + str(evaluator.evaluate(predictions_rf)*100)+\"%\")\n",
    "\n",
    "\n",
    "\n",
    "predictions = rfModel.transform(testData)\n",
    "predictions.filter(predictions['prediction'] == 0) \\\n",
    "    .select(\"value\",\"category\",\"probability\",\"label\",\"prediction\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(n = 10, truncate = 30)\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "print(\"-------Accuracy of test data using Random Forest-----: \" + str(evaluator.evaluate(predictions)*100)+\"%\")\n",
    "\n",
    "\n",
    "\n",
    "pipelineFit2 = pipeline.fit(unknown_data)\n",
    "unknown_dataset = pipelineFit2.transform(unknown_data)\n",
    "predictions2 = rfModel.transform(unknown_dataset)\n",
    "predictions2.filter(predictions2['prediction'] == 0) \\\n",
    "    .select(\"value\",\"category\",\"probability\",\"label\",\"prediction\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(n = 10, truncate = 30)\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "print(\"-------Accuracy of unknown data using Decision Tree-----: \" + str(evaluator.evaluate(predictions2)*100)+\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "736391ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+--------+------------------------------+-----+----------+\n",
      "|                         value|category|                   probability|label|prediction|\n",
      "+------------------------------+--------+------------------------------+-----+----------+\n",
      "|   Sections SEARCH Skip to ...|   Movie|[0.6398705677894322,0.13560...|  0.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...|   Movie|[0.6227305732576371,0.12748...|  0.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...|   Movie|[0.6227158003340711,0.15309...|  0.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...|   Movie|[0.6154696010362707,0.13968...|  0.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...|   Movie|[0.5852354309301614,0.15176...|  0.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...|   Movie|[0.5812419180480376,0.14512...|  0.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...|   Movie|[0.577175668620227,0.164575...|  0.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...|   Movie|[0.5765341565550058,0.16046...|  0.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...|   Movie|[0.5746639811963054,0.15903...|  0.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...|   Movie|[0.5742245313185417,0.17050...|  0.0|       0.0|\n",
      "+------------------------------+--------+------------------------------+-----+----------+\n",
      "only showing top 10 rows\n",
      "\n",
      "-------Accuracy of train data using Support Vector Machines-----: 66.78102182507108%\n",
      "+------------------------------+--------+------------------------------+-----+----------+\n",
      "|                         value|category|                   probability|label|prediction|\n",
      "+------------------------------+--------+------------------------------+-----+----------+\n",
      "|   Sections SEARCH Skip to ...|   Movie|[0.5734915360694213,0.16141...|  0.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...|   Movie|[0.5675465557586775,0.15006...|  0.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...|   Movie|[0.5482683483338631,0.17620...|  0.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...|   Movie|[0.5369476010768656,0.14659...|  0.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...|   Movie|[0.5244973064776545,0.17757...|  0.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...|   Movie|[0.4865085155160294,0.21724...|  0.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...|   Movie|[0.4829307582860207,0.23204...|  0.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...|   Movie|[0.47239848891421077,0.1739...|  0.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...|   Movie|[0.4694667794161258,0.21029...|  0.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...|   Movie|[0.4648452510077542,0.13808...|  0.0|       0.0|\n",
      "+------------------------------+--------+------------------------------+-----+----------+\n",
      "only showing top 10 rows\n",
      "\n",
      "-------Accuracy of test data using Support Vector Machines-----: 53.488746162139236%\n",
      "+------------------------------+--------+------------------------------+-----+----------+\n",
      "|                         value|category|                   probability|label|prediction|\n",
      "+------------------------------+--------+------------------------------+-----+----------+\n",
      "|   Sections SEARCH Skip to ...|   Movie|[0.34660649530416576,0.2772...|  0.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...|   Movie|[0.33908390638307784,0.2242...|  0.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...|   Movie|[0.32972099439480546,0.2512...|  0.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...| science|[0.3291258821252629,0.25405...|  1.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...| science|[0.3206019511525506,0.21386...|  1.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...|   Movie|[0.3177518743948406,0.23449...|  0.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...|   Movie|[0.31468145185962926,0.2389...|  0.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...| Fashion|[0.31468145185962926,0.2389...|  3.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...| science|[0.31468145185962926,0.2389...|  1.0|       0.0|\n",
      "|   Sections SEARCH Skip to ...|   Movie|[0.3128656912646792,0.26970...|  0.0|       0.0|\n",
      "+------------------------------+--------+------------------------------+-----+----------+\n",
      "only showing top 10 rows\n",
      "\n",
      "-------Accuracy of unknown data using Decision Tree-----: 37.18628490632733%\n"
     ]
    }
   ],
   "source": [
    "#training the data using Support Vector Machines\n",
    "from pyspark.ml.classification import LinearSVC\n",
    "pipelineFit_svc = pipeline.fit(data)\n",
    "dataset = pipelineFit_svc.transform(data)\n",
    "(trainingData, testData) = dataset.randomSplit([0.8, 0.2], seed = 100)\n",
    "svc = RandomForestClassifier(numTrees=50)\n",
    "svcModel = svc.fit(trainingData)\n",
    "\n",
    "predictions_svc = svcModel.transform(trainingData)\n",
    "predictions_svc.filter(predictions_svc['prediction'] == 0) \\\n",
    "    .select(\"value\",\"category\",\"probability\",\"label\",\"prediction\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(n = 10, truncate = 30)\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "print(\"-------Accuracy of train data using Support Vector Machines-----: \" + str(evaluator.evaluate(predictions_svc)*100)+\"%\")\n",
    "\n",
    "\n",
    "\n",
    "predictions = svcModel.transform(testData)\n",
    "predictions.filter(predictions['prediction'] == 0) \\\n",
    "    .select(\"value\",\"category\",\"probability\",\"label\",\"prediction\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(n = 10, truncate = 30)\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "print(\"-------Accuracy of test data using Support Vector Machines-----: \" + str(evaluator.evaluate(predictions)*100)+\"%\")\n",
    "\n",
    "\n",
    "\n",
    "pipelineFit2 = pipeline.fit(unknown_data)\n",
    "unknown_dataset = pipelineFit2.transform(unknown_data)\n",
    "predictions2 = svcModel.transform(unknown_dataset)\n",
    "predictions2.filter(predictions2['prediction'] == 0) \\\n",
    "    .select(\"value\",\"category\",\"probability\",\"label\",\"prediction\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(n = 10, truncate = 30)\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "print(\"-------Accuracy of unknown data using Decision Tree-----: \" + str(evaluator.evaluate(predictions2)*100)+\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e63a34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d239de4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
